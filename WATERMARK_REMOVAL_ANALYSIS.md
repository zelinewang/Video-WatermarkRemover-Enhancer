# ğŸ”¬ KLing æ°´å°ç§»é™¤é¡¹ç›®æŠ€æœ¯åˆ†æ

## ğŸ“Š é¡¹ç›®å·¥ä½œæµç¨‹å…¨è§£æ

### 1ï¸âƒ£ **æ•´ä½“æµç¨‹å›¾**

```
è§†é¢‘è¾“å…¥ (test1.mp4)
    â†“
[1] æå–å¸§ (extract_frames)
    â†’ ä½¿ç”¨ FFmpeg å°†è§†é¢‘åˆ†è§£ä¸º PNG å›¾åƒåºåˆ—
    â†’ test1/0001.png, 0002.png, ..., 0300.png
    â†“
[2] åˆ›å»ºæ°´å°æ©ç  (extract_mask)
    â†’ æ ¹æ®å›ºå®šä½ç½® [556, 1233, 701, 1267] åˆ›å»ºçŸ©å½¢æ©ç 
    â†’ ä¸ºæ¯ä¸€å¸§åˆ›å»ºå¯¹åº”çš„é»‘ç™½æ©ç å›¾åƒ
    â†“
[3] STTN è§†é¢‘ä¿®å¤ (inpaint_video)
    â†’ ä½¿ç”¨æ—¶ç©ºè½¬æ¢ç½‘ç»œåˆ†æç›¸é‚»å¸§
    â†’ æ ¹æ®æ©ç åŒºåŸŸè¿›è¡Œæ™ºèƒ½å¡«å……
    â†’ åˆ©ç”¨å‘¨å›´å¸§çš„æ—¶ç©ºä¿¡æ¯ä¿®å¤è¢«é®æŒ¡åŒºåŸŸ
    â†“
[4] ä¿å­˜ä¿®å¤å¸§ (inpaint_imag)
    â†’ å°†ä¿®å¤åçš„å¸§è¦†ç›–åŸå§‹å¸§æ–‡ä»¶
    â†“
[5] é‡æ–°åˆæˆè§†é¢‘ (create_video)
    â†’ ä½¿ç”¨ FFmpeg å°†å¸§åºåˆ—åˆæˆä¸ºè§†é¢‘
    â†’ âš ï¸ **è¿™é‡Œä¸¢å¤±äº†éŸ³é¢‘ï¼**
    â†“
è¾“å‡ºè§†é¢‘ (test1_enhanced.mp4) - æ— éŸ³é¢‘
```

---

## ğŸ¯ æ ¸å¿ƒæŠ€æœ¯è¯¦è§£

### 1. **æ°´å°ä½ç½®æ£€æµ‹ - å›ºå®šä½ç½®ç­–ç•¥**

**å½“å‰å®ç°**ï¼ˆ`config.yaml`ï¼‰ï¼š
```yaml
watermark:
  position: [556, 1233, 701, 1267]  # [x1, y1, x2, y2]
  mask_expand: 30                    # å‘å¤–æ‰©å±•30åƒç´ 
```

**å·¥ä½œåŸç†**ï¼š
```python
# modules/erase.py: extract_mask()
xmin, ymin, xmax, ymax = position  # å›ºå®šä½ç½®
mask = np.zeros(image.size[::-1], dtype="uint8")
cv2.rectangle(
    mask,
    (max(0, xmin - mask_expand), max(0, ymin - mask_expand)),
    (xmax + mask_expand, ymax + mask_expand),
    (255, 255, 255),  # ç™½è‰² = éœ€è¦ä¿®å¤çš„åŒºåŸŸ
    thickness=-1       # å¡«å……çŸ©å½¢
)
```

**å…³é”®ç‚¹**ï¼š
- âœ… **ä¼˜ç‚¹**ï¼šç®€å•é«˜æ•ˆï¼Œé€‚åˆå›ºå®šä½ç½®æ°´å°
- âŒ **å±€é™**ï¼š**æ— æ³•å¤„ç†åŠ¨æ€ä½ç½®æ°´å°**ï¼ˆå¦‚ Soraï¼‰
- ğŸ“ æ°´å°ä½ç½®åœ¨**æ‰€æœ‰å¸§ä¸­ä¿æŒä¸å˜**

---

### 2. **STTN è§†é¢‘ä¿®å¤ç®—æ³•**

**STTN = Spatio-Temporal Transformer Networkï¼ˆæ—¶ç©ºè½¬æ¢ç½‘ç»œï¼‰**

**æ ¸å¿ƒæ€æƒ³**ï¼š
```python
# modules/sttn.py: inpaint_video_with_builded_sttn()

# æ­¥éª¤ 1: ç‰¹å¾æå–
feats = model.encoder(frames)  # ç¼–ç æ‰€æœ‰å¸§çš„ç‰¹å¾

# æ­¥éª¤ 2: æ—¶ç©ºä¿®å¤ï¼ˆæ»‘åŠ¨çª—å£ï¼‰
for f in range(0, video_length, neighbor_stride):  # neighbor_stride = 10
    # è·å–ç›¸é‚»å¸§ ID
    neighbor_ids = [f-10, f-9, ..., f, ..., f+9, f+10]
    
    # è·å–å‚è€ƒå¸§ IDï¼ˆæ›´è¿œçš„å¸§ï¼‰
    ref_ids = get_ref_index(neighbor_ids, video_length)
    
    # ä½¿ç”¨ Transformer é¢„æµ‹ä¿®å¤å†…å®¹
    pred_feat = model.infer(
        feats[neighbor_ids + ref_ids],  # ç›¸é‚»å¸§ + å‚è€ƒå¸§
        masks[neighbor_ids + ref_ids]   # å¯¹åº”æ©ç 
    )
    
    # è§£ç ä¸ºå›¾åƒ
    pred_img = model.decoder(pred_feat)
    
    # æ··åˆåŸå§‹å¸§å’Œé¢„æµ‹å¸§
    comp_frame = pred_img * mask + original_frame * (1 - mask)
```

**æ—¶ç©ºä¿¡æ¯åˆ©ç”¨**ï¼š
1. **ç©ºé—´ä¿¡æ¯**ï¼šåŒä¸€å¸§å†…çš„å‘¨å›´åƒç´ 
2. **æ—¶é—´ä¿¡æ¯**ï¼šå‰åå¸§çš„å¯¹åº”ä½ç½®
3. **Transformer æ³¨æ„åŠ›**ï¼šå­¦ä¹ å¸§é—´å¯¹åº”å…³ç³»

**ä¸ºä»€ä¹ˆèƒ½å»é™¤æ°´å°**ï¼š
- æ°´å°åŒºåŸŸåœ¨ä¸åŒå¸§ä¸­ä½ç½®ç›¸åŒ
- ä½†æ°´å°**ä¸‹æ–¹çš„å†…å®¹åœ¨è¿åŠ¨**
- STTN é€šè¿‡åˆ†æç›¸é‚»å¸§çš„è¿åŠ¨æ¨¡å¼
- æ¨æ–­å‡ºæ°´å°ä¸‹æ–¹"åº”è¯¥"æœ‰ä»€ä¹ˆå†…å®¹

---

### 3. **éŸ³é¢‘å¤„ç†é—®é¢˜**

**å½“å‰é—®é¢˜**ï¼š
```python
# utils/video_utils.py: extract_frames()
# âŒ åªæå–è§†é¢‘æµï¼Œä¸ä¿å­˜éŸ³é¢‘
commands = ["-i", target_path, "-q:v", str(temp_frame_quality), ...]

# utils/video_utils.py: create_video()
# âŒ é‡æ–°åˆæˆæ—¶æ²¡æœ‰æ·»åŠ éŸ³é¢‘æµ
commands = [
    "-i", frame_sequence,
    "-c:v", "libx264",  # åªæœ‰è§†é¢‘ç¼–ç å™¨
    "-y", output_path
]
```

**ä¸ºä»€ä¹ˆä¸¢å¤±éŸ³é¢‘**ï¼š
- æå–å¸§æ—¶ï¼šåªå¤„ç†è§†é¢‘æµ (`-v:0`)
- åˆæˆè§†é¢‘æ—¶ï¼šåªä»å¸§åºåˆ—åˆ›å»ºè§†é¢‘ï¼Œæ²¡æœ‰æ··å…¥åŸéŸ³é¢‘

---

## ğŸ”§ ä¿®æ”¹æ–¹æ¡ˆï¼šæ”¯æŒåŠ¨æ€æ°´å°ï¼ˆå¦‚ Soraï¼‰

### **æŒ‘æˆ˜åˆ†æ**

| æ°´å°ç±»å‹ | KLing æ°´å° | Sora æ°´å° |
|---------|-----------|----------|
| **ä½ç½®** | å›ºå®šä¸å˜ | éšæ—¶é—´å˜åŒ– |
| **æ£€æµ‹éš¾åº¦** | ç®€å• | å›°éš¾ |
| **ä¿®å¤ç­–ç•¥** | å›ºå®šæ©ç  | éœ€è¦é€å¸§æ£€æµ‹ |

### **æ–¹æ¡ˆ 1ï¼šåŸºäºæ¨¡æ¿åŒ¹é…çš„åŠ¨æ€æ£€æµ‹** â­

**é€‚ç”¨åœºæ™¯**ï¼šæ°´å°å›¾æ¡ˆå›ºå®šï¼Œåªæ˜¯ä½ç½®å˜åŒ–

```python
# åˆ›å»ºæ–°æ–‡ä»¶: utils/watermark_detection.py

import cv2
import numpy as np
from typing import List, Tuple

def detect_watermark_template(
    frame: np.ndarray,
    template: np.ndarray,
    threshold: float = 0.8
) -> Tuple[int, int, int, int]:
    """
    ä½¿ç”¨æ¨¡æ¿åŒ¹é…æ£€æµ‹æ°´å°ä½ç½®
    
    Args:
        frame: è§†é¢‘å¸§
        template: æ°´å°æ¨¡æ¿å›¾åƒ
        threshold: åŒ¹é…é˜ˆå€¼
    
    Returns:
        (x1, y1, x2, y2) æ°´å°è¾¹ç•Œæ¡†
    """
    # è½¬æ¢ä¸ºç°åº¦
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray_template = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)
    
    # æ¨¡æ¿åŒ¹é…
    result = cv2.matchTemplate(gray_frame, gray_template, cv2.TM_CCOEFF_NORMED)
    
    # æ‰¾åˆ°æœ€ä½³åŒ¹é…ä½ç½®
    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
    
    if max_val >= threshold:
        h, w = gray_template.shape
        x1, y1 = max_loc
        x2, y2 = x1 + w, y1 + h
        return (x1, y1, x2, y2)
    else:
        return None  # æœªæ£€æµ‹åˆ°æ°´å°

def detect_watermarks_in_video(
    frame_paths: List[str],
    template_path: str,
    mask_expand: int = 30
) -> List[Tuple[int, int, int, int]]:
    """
    ä¸ºæ¯ä¸€å¸§æ£€æµ‹æ°´å°ä½ç½®
    
    Returns:
        æ¯å¸§çš„æ°´å°ä½ç½®åˆ—è¡¨
    """
    template = cv2.imread(template_path)
    positions = []
    
    for frame_path in tqdm(frame_paths, desc="Detecting watermark"):
        frame = cv2.imread(frame_path)
        position = detect_watermark_template(frame, template)
        
        if position:
            # æ‰©å±•æ©ç åŒºåŸŸ
            x1, y1, x2, y2 = position
            x1 = max(0, x1 - mask_expand)
            y1 = max(0, y1 - mask_expand)
            x2 = min(frame.shape[1], x2 + mask_expand)
            y2 = min(frame.shape[0], y2 + mask_expand)
            positions.append((x1, y1, x2, y2))
        else:
            positions.append(None)  # è¯¥å¸§æ— æ°´å°
    
    return positions
```

**ä¿®æ”¹ `modules/erase.py`**ï¼š

```python
def extract_mask_dynamic(
    frame_paths: List[str],
    positions: List[Tuple[int, int, int, int]],  # æ¯å¸§ä¸åŒçš„ä½ç½®
    mask_expand: int = 20,
):
    """
    ä¸ºæ¯å¸§åˆ›å»ºåŠ¨æ€æ©ç 
    """
    frames_list = []
    masks_list = []
    
    for frame_path, position in tqdm(
        zip(frame_paths, positions), 
        desc="Set Dynamic Mask",
        total=len(frame_paths)
    ):
        image = load_img(frame_path)
        mask = np.zeros(image.size[::-1], dtype="uint8")
        
        if position:  # å¦‚æœè¯¥å¸§æœ‰æ°´å°
            xmin, ymin, xmax, ymax = position
            cv2.rectangle(
                mask,
                (xmin, ymin),
                (xmax, ymax),
                (255, 255, 255),
                thickness=-1,
            )
        # else: è¯¥å¸§æ— æ°´å°ï¼Œæ©ç å…¨é»‘
        
        mask = Image.fromarray(mask)
        frames_list.append(image)
        masks_list.append(mask)
    
    return frames_list, masks_list

def remove_watermark_dynamic(
    frame_paths: List[str],
    template_path: str  # Sora æ°´å°æ¨¡æ¿å›¾åƒè·¯å¾„
):
    """
    ç§»é™¤åŠ¨æ€ä½ç½®æ°´å°
    """
    # 1. æ£€æµ‹æ¯å¸§çš„æ°´å°ä½ç½®
    positions = detect_watermarks_in_video(
        frame_paths, 
        template_path,
        CONFIG["watermark"]["mask_expand"]
    )
    
    # 2. åˆ›å»ºåŠ¨æ€æ©ç 
    frames_list, masks_list = extract_mask_dynamic(
        frame_paths, 
        positions,
        CONFIG["watermark"]["mask_expand"]
    )
    
    # 3. STTN ä¿®å¤
    results = inpaint_video(
        frame_paths,
        frames_list,
        masks_list,
        CONFIG["watermark"]["neighbor_stride"],
        CONFIG["watermark"]["ckpt_p"],
    )
    
    # 4. ä¿å­˜ç»“æœ
    inpaint_imag(results)
```

---

### **æ–¹æ¡ˆ 2ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„æ°´å°æ£€æµ‹** ğŸš€

**é€‚ç”¨åœºæ™¯**ï¼šæ°´å°å½¢çŠ¶ã€å¤§å°ã€é€æ˜åº¦éƒ½å¯èƒ½å˜åŒ–

```python
# ä½¿ç”¨ YOLOv8 æˆ–å…¶ä»–ç›®æ ‡æ£€æµ‹æ¨¡å‹

from ultralytics import YOLO

def detect_watermark_yolo(
    frame: np.ndarray,
    model: YOLO
) -> Tuple[int, int, int, int]:
    """
    ä½¿ç”¨ YOLO æ£€æµ‹æ°´å°
    
    éœ€è¦å…ˆè®­ç»ƒ YOLO æ¨¡å‹è¯†åˆ« Sora æ°´å°
    """
    results = model(frame)
    
    for result in results:
        boxes = result.boxes
        for box in boxes:
            if box.cls == 0:  # å‡è®¾ç±»åˆ« 0 æ˜¯æ°´å°
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                return (int(x1), int(y1), int(x2), int(y2))
    
    return None

# è®­ç»ƒæ•°æ®å‡†å¤‡
# 1. æ”¶é›†åŒ…å« Sora æ°´å°çš„è§†é¢‘å¸§
# 2. æ‰‹åŠ¨æ ‡æ³¨æ°´å°ä½ç½®ï¼ˆä½¿ç”¨ LabelImg ç­‰å·¥å…·ï¼‰
# 3. è®­ç»ƒ YOLOv8 æ¨¡å‹
# 4. åœ¨æ¨ç†æ—¶ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹
```

---

### **æ–¹æ¡ˆ 3ï¼šåŸºäºé¢‘åŸŸåˆ†æ** ğŸ”¬

**åŸç†**ï¼šæ°´å°é€šå¸¸åœ¨é¢‘åŸŸæœ‰ç‰¹å®šæ¨¡å¼

```python
import cv2
import numpy as np

def detect_watermark_frequency(frame: np.ndarray) -> np.ndarray:
    """
    åŸºäº DFTï¼ˆç¦»æ•£å‚…é‡Œå¶å˜æ¢ï¼‰æ£€æµ‹æ°´å°
    """
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # å‚…é‡Œå¶å˜æ¢
    dft = cv2.dft(np.float32(gray), flags=cv2.DFT_COMPLEX_OUTPUT)
    dft_shift = np.fft.fftshift(dft)
    
    # åˆ†æé¢‘è°±ï¼Œæ£€æµ‹æ°´å°ç‰¹å¾
    magnitude = 20 * np.log(cv2.magnitude(dft_shift[:,:,0], dft_shift[:,:,1]))
    
    # ... æ°´å°æ£€æµ‹é€»è¾‘ ...
    
    return watermark_mask
```

---

## ğŸµ ä¿®æ”¹æ–¹æ¡ˆï¼šä¿ç•™éŸ³é¢‘

### **æ–¹æ¡ˆ 1ï¼šåˆ†ç¦»éŸ³é¢‘ â†’ å¤„ç†è§†é¢‘ â†’ åˆå¹¶** â­ æ¨è

```python
# ä¿®æ”¹ utils/video_utils.py

def extract_audio(video_path: str, audio_path: str) -> bool:
    """
    ä»è§†é¢‘ä¸­æå–éŸ³é¢‘
    """
    commands = [
        "-i", video_path,
        "-vn",  # ä¸å¤„ç†è§†é¢‘
        "-acodec", "copy",  # ç›´æ¥å¤åˆ¶éŸ³é¢‘æµ
        audio_path
    ]
    return run_ffmpeg(commands)

def merge_video_audio(
    video_path: str,
    audio_path: str,
    output_path: str
) -> bool:
    """
    åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
    """
    commands = [
        "-i", video_path,
        "-i", audio_path,
        "-c:v", "copy",  # å¤åˆ¶è§†é¢‘æµ
        "-c:a", "aac",   # éŸ³é¢‘ç¼–ç 
        "-map", "0:v:0",  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¾“å…¥çš„è§†é¢‘æµ
        "-map", "1:a:0",  # ä½¿ç”¨ç¬¬äºŒä¸ªè¾“å…¥çš„éŸ³é¢‘æµ
        "-shortest",      # ä»¥è¾ƒçŸ­çš„æµä¸ºå‡†
        "-y", output_path
    ]
    return run_ffmpeg(commands)

def create_video_with_audio(
    target_path: str,
    output_path: str,
    fps: float = 30,
    output_video_encoder: str = "libx264",
) -> bool:
    """
    åˆ›å»ºå¸¦éŸ³é¢‘çš„è§†é¢‘
    """
    temp_directory_path = get_temp_directory_path(target_path)
    temp_video_path = output_path.replace(".mp4", "_no_audio.mp4")
    temp_audio_path = output_path.replace(".mp4", "_audio.aac")
    
    # 1. æå–åŸå§‹éŸ³é¢‘
    extract_audio(target_path, temp_audio_path)
    
    # 2. ä»å¸§åˆ›å»ºæ— éŸ³é¢‘è§†é¢‘
    commands = [
        "-hwaccel", "auto",
        "-r", str(fps),
        "-i", os.path.join(temp_directory_path, "%04d." + TEMP_FRAME_FORMAT),
        "-c:v", output_video_encoder,
        "-pix_fmt", "yuv420p",
        "-vf", "pad=ceil(iw/2)*2:ceil(ih/2)*2",
        "-y", temp_video_path
    ]
    run_ffmpeg(commands)
    
    # 3. åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
    merge_video_audio(temp_video_path, temp_audio_path, output_path)
    
    # 4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists(temp_video_path):
        os.remove(temp_video_path)
    if os.path.exists(temp_audio_path):
        os.remove(temp_audio_path)
    
    return True
```

**ä¿®æ”¹ `main.py`**ï¼š

```python
def process_video(
    input_path: str,
    output_path: str,
    remove_watermark_flag: bool,
    enhance_video_flag: bool,
    keep_audio: bool = True,  # æ–°å¢å‚æ•°
):
    # ... å‰é¢çš„å¤„ç† ...
    
    if keep_audio:
        update_status("Create video with audio")
        create_video_with_audio(input_path, output_path, fps)
    else:
        update_status("Create video (no audio)")
        create_video(input_path, output_path, fps)
```

---

### **æ–¹æ¡ˆ 2ï¼šç›´æ¥å¤„ç†å¸¦éŸ³é¢‘çš„æµ** 

```python
def create_video_preserve_audio(
    target_path: str,
    output_path: str,
    fps: float = 30,
) -> bool:
    """
    åœ¨åˆ›å»ºè§†é¢‘æ—¶ç›´æ¥ä¿ç•™åŸå§‹éŸ³é¢‘
    """
    temp_directory_path = get_temp_directory_path(target_path)
    
    commands = [
        "-hwaccel", "auto",
        "-r", str(fps),
        "-i", os.path.join(temp_directory_path, "%04d." + TEMP_FRAME_FORMAT),
        "-i", target_path,  # åŸå§‹è§†é¢‘ï¼ˆæä¾›éŸ³é¢‘ï¼‰
        "-c:v", "libx264",
        "-pix_fmt", "yuv420p",
        "-vf", "pad=ceil(iw/2)*2:ceil(ih/2)*2",
        "-c:a", "copy",  # ç›´æ¥å¤åˆ¶éŸ³é¢‘æµ
        "-map", "0:v:0",  # ä½¿ç”¨æ–°å¸§ä½œä¸ºè§†é¢‘
        "-map", "1:a:0?",  # ä½¿ç”¨åŸè§†é¢‘çš„éŸ³é¢‘ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        "-shortest",
        "-y", output_path
    ]
    
    return run_ffmpeg(commands)
```

---

## ğŸ“ é…ç½®æ–‡ä»¶æ›´æ–°

### æ–°å¢ `config.yaml` é…ç½®é¡¹

```yaml
watermark:
  # åŸæœ‰é…ç½®
  position: [556, 1233, 701, 1267]
  ckpt_p: "./weights/sttn.pth"
  mask_expand: 30
  neighbor_stride: 10
  
  # æ–°å¢ï¼šåŠ¨æ€æ°´å°é…ç½®
  dynamic: false  # æ˜¯å¦ä¸ºåŠ¨æ€æ°´å°
  template_path: ""  # æ°´å°æ¨¡æ¿å›¾åƒè·¯å¾„ï¼ˆç”¨äºæ£€æµ‹ï¼‰
  detection_method: "template"  # template | yolo | frequency

audio:
  # æ–°å¢ï¼šéŸ³é¢‘å¤„ç†é…ç½®
  keep_audio: true  # æ˜¯å¦ä¿ç•™éŸ³é¢‘
  audio_codec: "aac"  # éŸ³é¢‘ç¼–ç å™¨
  audio_bitrate: "192k"  # éŸ³é¢‘æ¯”ç‰¹ç‡

enhance:
  RealESRGAN_model_path: "./weights/RealESRGAN_x2plus.pth"
  GFPGANer_model_path: "./weights/GFPGANv1.4.pth"
```

---

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šç§»é™¤å›ºå®šä½ç½®æ°´å°ï¼ˆKLingï¼‰+ ä¿ç•™éŸ³é¢‘

```bash
python main.py --input video.mp4 --remove-watermark --keep-audio
```

### ç¤ºä¾‹ 2ï¼šç§»é™¤åŠ¨æ€æ°´å°ï¼ˆSoraï¼‰

```bash
# 1. å‡†å¤‡ Sora æ°´å°æ¨¡æ¿
# æˆªå–ä¸€å¸§ä¸­çš„ Sora æ°´å°ï¼Œä¿å­˜ä¸º sora_template.png

# 2. æ›´æ–° config.yaml
# watermark:
#   dynamic: true
#   template_path: "./sora_template.png"

# 3. è¿è¡Œ
python main.py --input sora_video.mp4 --remove-watermark --keep-audio
```

### ç¤ºä¾‹ 3ï¼šä½¿ç”¨ YOLO æ£€æµ‹æ°´å°

```bash
# 1. è®­ç»ƒ YOLO æ¨¡å‹ï¼ˆéœ€è¦æ ‡æ³¨æ•°æ®ï¼‰
# 2. æ›´æ–° config.yaml
# watermark:
#   dynamic: true
#   detection_method: "yolo"
#   yolo_model_path: "./weights/watermark_yolo.pt"

# 3. è¿è¡Œ
python main.py --input video.mp4 --remove-watermark
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| å¤„ç†æ–¹å¼ | å›ºå®šæ°´å° | åŠ¨æ€æ°´å°ï¼ˆæ¨¡æ¿åŒ¹é…ï¼‰ | åŠ¨æ€æ°´å°ï¼ˆYOLOï¼‰ |
|---------|---------|-------------------|----------------|
| **æ£€æµ‹é€Ÿåº¦** | å³æ—¶ | ä¸­ç­‰ï¼ˆ~50 FPSï¼‰ | æ…¢ï¼ˆ~10-20 FPSï¼‰ |
| **å‡†ç¡®ç‡** | 100% | 85-95% | 90-98% |
| **é€‚ç”¨åœºæ™¯** | ä½ç½®å›ºå®š | æ°´å°æ ·å¼å›ºå®š | æ°´å°å¤šå˜ |
| **GPU éœ€æ±‚** | ä½ | ä½ | é«˜ |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. åŠ¨æ€æ°´å°æ£€æµ‹çš„æŒ‘æˆ˜
- **é®æŒ¡é—®é¢˜**ï¼šæ°´å°å¯èƒ½è¢«è§†é¢‘å†…å®¹éƒ¨åˆ†é®æŒ¡
- **äº®åº¦å˜åŒ–**ï¼šè§†é¢‘åœºæ™¯å˜åŒ–å½±å“æ£€æµ‹å‡†ç¡®ç‡
- **è¿åŠ¨æ¨¡ç³Š**ï¼šå¿«é€Ÿè¿åŠ¨æ—¶æ°´å°å¯èƒ½æ¨¡ç³Š

### 2. éŸ³é¢‘åŒæ­¥
- **æ—¶é•¿åŒ¹é…**ï¼šç¡®ä¿å¤„ç†åè§†é¢‘æ—¶é•¿ä¸åŸè§†é¢‘ä¸€è‡´
- **é‡‡æ ·ç‡**ï¼šä¿æŒéŸ³é¢‘é‡‡æ ·ç‡ä¸å˜
- **å»¶è¿Ÿé—®é¢˜**ï¼šå¯èƒ½éœ€è¦å¾®è°ƒéŸ³è§†é¢‘åŒæ­¥

### 3. STTN æ¨¡å‹é™åˆ¶
- **è®¡ç®—æˆæœ¬**ï¼šå¤„ç†åŠ¨æ€æ©ç å¯èƒ½æ›´æ…¢
- **ä¿®å¤è´¨é‡**ï¼šæ©ç åŒºåŸŸè¶Šå¤§ï¼Œä¿®å¤è´¨é‡è¶Šå·®
- **è¾¹ç¼˜ä¼ªå½±**ï¼šmask_expand éœ€è¦æ ¹æ®æ°´å°è°ƒæ•´

---

## ğŸ” è°ƒè¯•å’Œä¼˜åŒ–å»ºè®®

### 1. å¯è§†åŒ–æ°´å°æ£€æµ‹
```python
# ä¿å­˜æ£€æµ‹åˆ°çš„æ©ç ä»¥ä¾›æ£€æŸ¥
cv2.imwrite(f"debug_mask_{frame_idx}.png", mask)
```

### 2. æ‰¹å¤„ç†ä¼˜åŒ–
```python
# ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿæ°´å°æ£€æµ‹
from multiprocessing import Pool

def detect_batch(frame_paths_chunk):
    # æ£€æµ‹é€»è¾‘
    pass

with Pool(processes=4) as pool:
    results = pool.map(detect_batch, chunks)
```

### 3. å¢é‡å¤„ç†
```python
# åªå¤„ç†æ£€æµ‹åˆ°æ°´å°çš„å¸§
frames_with_watermark = [i for i, pos in enumerate(positions) if pos]
# ä»…ä¿®å¤è¿™äº›å¸§ï¼Œå…¶ä»–å¸§ä¿æŒä¸å˜
```

---

## ğŸ“š ç›¸å…³èµ„æº

- [STTN è®ºæ–‡](https://arxiv.org/abs/2204.01653)
- [OpenCV æ¨¡æ¿åŒ¹é…æ–‡æ¡£](https://docs.opencv.org/4.x/d4/dc6/tutorial_py_template_matching.html)
- [YOLOv8 å®˜æ–¹æ–‡æ¡£](https://docs.ultralytics.com/)
- [FFmpeg éŸ³è§†é¢‘å¤„ç†æŒ‡å—](https://ffmpeg.org/documentation.html)

---

å¦‚æœéœ€è¦å…·ä½“å®ç°ä»£ç æˆ–é‡åˆ°é—®é¢˜ï¼Œè¯·å‚è€ƒæœ¬æ–‡æ¡£æˆ–æŸ¥çœ‹é¡¹ç›® Issuesã€‚

